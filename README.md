# AI Knowledge Graph for Legal Texts

AutomatickÃ¡ extrakcia a prepojenie informÃ¡ciÃ­ z prÃ¡vnych textov do interaktÃ­vneho znalostnÃ©ho grafu.

## ðŸ“‹ Obsah

- [PrehÄ¾ad](#prehÄ¾ad)
- [ArchitektÃºra](#architektÃºra)
- [TechnologickÃ½ Stack](#technologickÃ½-stack)
- [InÅ¡talÃ¡cia](#inÅ¡talÃ¡cia)
- [ImplementÃ¡cia](#implementÃ¡cia)
- [Komponenty](#komponenty)
- [Å tudijnÃ© MateriÃ¡ly](#Å¡tudijnÃ©-materiÃ¡ly)
- [MVP Prototyp](#mvp-prototyp)
- [Roadmap](#roadmap)

## ðŸŽ¯ PrehÄ¾ad

CieÄ¾om projektu je vytvoriÅ¥ AI systÃ©m na automatickÃº extrakciu a prepojenie informÃ¡ciÃ­ z prÃ¡vnych textov do znalostnÃ©ho grafu. VÃ½sledkom je interaktÃ­vny graf znÃ¡zorÅˆujÃºcy vÃ¤zby medzi prÃ¡vnymi pojmami a ustanoveniami v zÃ¡kone.

### HlavnÃ© funkcie

- ðŸ” AutomatickÃ¡ extrakcia prÃ¡vnych entÃ­t (paragrafy, pojmy, inÅ¡titÃºcie)
- ðŸ”— IdentifikÃ¡cia vzÅ¥ahov medzi prÃ¡vnymi ustanoveniami
- ðŸ“Š VizualizÃ¡cia znalostnÃ©ho grafu
- ðŸ”Ž InteraktÃ­vne prehÄ¾adÃ¡vanie a explorÃ¡cia
- ðŸ’¬ SÃ©mantickÃ© vyhÄ¾adÃ¡vanie a Q&A

## ðŸ—ï¸ ArchitektÃºra

### Tri-fÃ¡zovÃ½ proces

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ FÃZA 1: Spracovanie a Extrakcia                             â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ PrÃ¡vny text â†’ Preprocessing â†’ NER & Relation Extraction     â”‚
â”‚                              â†’ Å truktÃºrovanÃ© dÃ¡ta            â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                            â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ FÃZA 2: KonÅ¡trukcia Grafu                                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Å truktÃºrovanÃ© dÃ¡ta â†’ Graph Building                         â”‚
â”‚                    â†’ Knowledge Graph (Neo4j/NetworkX)        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                            â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ FÃZA 3: VizualizÃ¡cia a Interakcia                           â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Knowledge Graph â†’ Query & Visualization                     â”‚
â”‚                 â†’ InteraktÃ­vne rozhranie                     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## ðŸ› ï¸ TechnologickÃ½ Stack

### Core Frameworky

| Komponent | TechnolÃ³gia | ÃšÄel |
|-----------|-------------|------|
| **AI OrchestrÃ¡cia** | LangGraph + LangChain | Workflow management, multi-step processing |
| **LLM** | OpenAI API / Anthropic Claude | Entity & relation extraction |
| **NLP** | Spacy (`sk_core_news_lg`) | Preprocessing, tokenizÃ¡cia, NER |
| **Graph DB** | Neo4j | ÃšloÅ¾isko znalostnÃ©ho grafu |
| **VizualizÃ¡cia** | Pyvis, Plotly, D3.js | InteraktÃ­vne grafy |
| **Web Framework** | FastAPI / Dash | API a dashboard |

### DoplnkovÃ© nÃ¡stroje

- **Hugging Face Transformers** - Fine-tuning modelov
- **NetworkX** - Graph manipulation v Pythone
- **ArangoDB / Amazon Neptune** - AlternatÃ­vne graph DB
- **Docker** - KontajnerizÃ¡cia

## ðŸ“¦ InÅ¡talÃ¡cia

### PoÅ¾iadavky

```bash
Python 3.9+
Neo4j 5.0+
```

### Setup

```bash
# Clone repository
git clone https://github.com/your-username/legal-knowledge-graph.git
cd legal-knowledge-graph

# Vytvorenie virtual environment
python -m venv venv
source venv/bin/activate  # Linux/Mac
# venv\Scripts\activate  # Windows

# InÅ¡talÃ¡cia zÃ¡vislostÃ­
pip install -r requirements.txt

# Download Spacy Slovak model
python -m spacy download sk_core_news_lg

# Setup Neo4j (Docker)
docker run -d \
  --name neo4j-legal \
  -p 7474:7474 -p 7687:7687 \
  -e NEO4J_AUTH=neo4j/password \
  neo4j:latest
```

### requirements.txt

```txt
langchain>=0.1.0
langgraph>=0.0.20
openai>=1.0.0
anthropic>=0.8.0
spacy>=3.7.0
neo4j>=5.14.0
networkx>=3.2
pyvis>=0.3.2
plotly>=5.18.0
dash>=2.14.0
fastapi>=0.104.0
uvicorn>=0.24.0
python-dotenv>=1.0.0
pydantic>=2.5.0
```

## ðŸ’» ImplementÃ¡cia

### Krok 1: Data Pipeline

```python
# legal_processor.py

from typing import List, Dict
import spacy
from dataclasses import dataclass

@dataclass
class Entity:
    text: str
    type: str
    context: str
    span: tuple

@dataclass
class Relation:
    source: str
    target: str
    type: str
    confidence: float

class LegalDocumentProcessor:
    def __init__(self):
        self.nlp = spacy.load("sk_core_news_lg")
    
    def preprocess(self, text: str) -> Dict:
        """
        ÄŒistenie a segmentÃ¡cia prÃ¡vneho textu
        - Rozpoznanie Â§, odsekov, bodov
        - NormalizÃ¡cia textu
        """
        # ImplementÃ¡cia preprocessing logiky
        pass
    
    def extract_entities(self, text: str) -> List[Entity]:
        """
        NER: prÃ¡vne pojmy, inÅ¡titÃºcie, Â§ ÄÃ­sla
        VyuÅ¾itie LLM-based extraction
        """
        # ImplementÃ¡cia entity extraction
        pass
    
    def extract_relations(self, entities: List[Entity], 
                         context: str) -> List[Relation]:
        """
        Extrakcia vzÅ¥ahov medzi entitami
        Typy: odkazuje_na, definuje, upravuje
        """
        # ImplementÃ¡cia relation extraction
        pass
```

### Krok 2: LangGraph Workflow

```python
# workflow.py

from langgraph.graph import StateGraph
from typing import TypedDict, List
import networkx as nx

class GraphState(TypedDict):
    document: str
    entities: List[Entity]
    relations: List[Relation]
    graph: nx.Graph
    metadata: Dict

def parse_legal_document(state: GraphState) -> GraphState:
    """Parse a segmentuj prÃ¡vny dokument"""
    # ImplementÃ¡cia
    return state

def entity_extraction(state: GraphState) -> GraphState:
    """Extrahuj prÃ¡vne entity"""
    # ImplementÃ¡cia
    return state

def relation_extraction(state: GraphState) -> GraphState:
    """Extrahuj vzÅ¥ahy medzi entitami"""
    # ImplementÃ¡cia
    return state

def construct_knowledge_graph(state: GraphState) -> GraphState:
    """Vybuduj znalostnÃ½ graf"""
    # ImplementÃ¡cia
    return state

# DefinÃ­cia workflow
workflow = StateGraph(GraphState)

# Pridanie nodov
workflow.add_node("parse", parse_legal_document)
workflow.add_node("extract_entities", entity_extraction)
workflow.add_node("extract_relations", relation_extraction)
workflow.add_node("build_graph", construct_knowledge_graph)

# Pridanie edges
workflow.add_edge("parse", "extract_entities")
workflow.add_edge("extract_entities", "extract_relations")
workflow.add_edge("extract_relations", "build_graph")

# Compile
app = workflow.compile()
```

### Krok 3: Prompt Engineering

```python
# prompts.py

ENTITY_EXTRACTION_PROMPT = """
Analyzuj tento slovenskÃ½ prÃ¡vny text a identifikuj:

1. **PrÃ¡vne pojmy** (napr. "zmluva", "nÃ¡hrada Å¡kody", "zodpovednosÅ¥")
2. **Odkazy na paragrafy** (Â§ X, Â§ Y ods. Z)
3. **PrÃ¡vne inÅ¡titÃºcie** (sÃºd, orgÃ¡n, komisia)
4. **Subjekty prÃ¡va** (fyzickÃ¡ osoba, prÃ¡vnickÃ¡ osoba)

Text: {legal_text}

VrÃ¡Å¥ vÃ½sledok v JSON formÃ¡te:
{{
    "entities": [
        {{
            "text": "nÃ¡zov entity",
            "type": "LEGAL_CONCEPT|PARAGRAPH|INSTITUTION|SUBJECT",
            "context": "kontext vÃ½skytu",
            "span": [start, end]
        }}
    ]
}}
"""

RELATION_EXTRACTION_PROMPT = """
Pre nasledujÃºce entity z prÃ¡vneho textu identifikuj vzÅ¥ahy medzi nimi.

**Entities:** {entities}

**Kontext:** {context}

**Typy vzÅ¥ahov:**
- ODKAZUJE_NA: Â§ X odkazuje na Â§ Y
- DEFINUJE: Â§ X definuje pojem Y
- UPRAVUJE: Â§ X upravuje oblasÅ¥ Y
- RUÅ UJE: Â§ X ruÅ¡Ã­ ustanovenie Y
- DOPLÅ‡UJE: Â§ X dopÄºÅˆa Â§ Y
- PODMIEÅ‡UJE: Â§ X podmieÅˆuje Â§ Y

VrÃ¡Å¥ vÃ½sledok v JSON formÃ¡te:
{{
    "relations": [
        {{
            "from": "source entity",
            "to": "target entity",
            "type": "RELATION_TYPE",
            "confidence": 0.0-1.0,
            "evidence": "textovÃ½ dÃ´kaz"
        }}
    ]
}}
"""
```

### Krok 4: Neo4j Integration

```python
# graph_store.py

from neo4j import GraphDatabase
from typing import List

class LegalKnowledgeGraph:
    def __init__(self, uri: str, user: str, password: str):
        self.driver = GraphDatabase.driver(uri, auth=(user, password))
    
    def close(self):
        self.driver.close()
    
    def create_entity(self, entity: Entity):
        """Vytvor node v grafe"""
        with self.driver.session() as session:
            session.run(
                """
                CREATE (e:Entity {
                    text: $text,
                    type: $type,
                    context: $context
                })
                """,
                text=entity.text,
                type=entity.type,
                context=entity.context
            )
    
    def create_relation(self, relation: Relation):
        """Vytvor edge v grafe"""
        with self.driver.session() as session:
            session.run(
                """
                MATCH (a:Entity {text: $source})
                MATCH (b:Entity {text: $target})
                CREATE (a)-[r:RELATES_TO {
                    type: $type,
                    confidence: $confidence
                }]->(b)
                """,
                source=relation.source,
                target=relation.target,
                type=relation.type,
                confidence=relation.confidence
            )
    
    def query_related_entities(self, entity_text: str, depth: int = 2):
        """NÃ¡jdi prepojenÃ© entity"""
        with self.driver.session() as session:
            result = session.run(
                """
                MATCH path = (e:Entity {text: $text})-[*1..$depth]-(related)
                RETURN path
                """,
                text=entity_text,
                depth=depth
            )
            return [record["path"] for record in result]
```

## ðŸ§© Komponenty

### Entity Recognition

| Typ Entity | PrÃ­klady | Popis |
|------------|----------|-------|
| **LEGAL_CONCEPT** | zmluva, zodpovednosÅ¥, prÃ¡vo | PrÃ¡vne pojmy |
| **PARAGRAPH** | Â§ 123, Â§ 45 ods. 2 pÃ­sm. a) | Odkazy na paragrafy |
| **SUBJECT** | fyzickÃ¡ osoba, prÃ¡vnickÃ¡ osoba | Subjekty prÃ¡va |
| **INSTITUTION** | sÃºd, ministerstvo, komisia | PrÃ¡vne inÅ¡titÃºcie |
| **DOCUMENT** | zÃ¡kon, vyhlÃ¡Å¡ka, nariadenie | Typy dokumentov |

### Relation Types

```python
RELATION_TYPES = {
    "ODKAZUJE_NA": "Â§ X odkazuje na Â§ Y",
    "DEFINUJE": "Â§ X definuje pojem Y",
    "UPRAVUJE": "Â§ X upravuje oblasÅ¥ Y",
    "RUÅ UJE": "Â§ X ruÅ¡Ã­ Â§ Y",
    "DOPLÅ‡UJE": "Â§ X dopÄºÅˆa Â§ Y",
    "PODMIEÅ‡UJE": "Â§ X podmieÅˆuje Â§ Y",
    "VYLUÄŒUJE": "Â§ X vyluÄuje aplikÃ¡ciu Â§ Y",
    "SPRESÅ‡UJE": "Â§ X spresÅˆuje Â§ Y"
}
```

## ðŸ“š Å tudijnÃ© MateriÃ¡ly

### LangGraph & LangChain

- ðŸ“– [LangGraph Official Documentation](https://langchain-ai.github.io/langgraph/)
- ðŸŽ¥ Tutorial: "Building Knowledge Graphs with LangChain"
- ðŸ’» [GitHub: langgraph-examples](https://github.com/langchain-ai/langgraph/tree/main/examples)
- ðŸ“ [LangChain Cookbook](https://github.com/langchain-ai/langchain/tree/master/cookbook)

### Knowledge Graphs & NLP

- ðŸ“˜ **Kniha:** "Knowledge Graphs" - Hogan et al. (2021)
- ðŸ“„ **Paper:** "Construction of the Literature Graph in Semantic Scholar" (2018)
- ðŸŽ“ **Course:** Stanford CS224W - Machine Learning with Graphs
- ðŸ“Š **Tutorial:** "Knowledge Graph Construction from Text" - ACL 2020

### Legal NLP

- ðŸ›ï¸ **Workshop:** Natural Legal Language Processing (NLLP)
- ðŸ“¦ **Library:** [LexNLP](https://github.com/LexPredict/lexpredict-lexnlp) - Legal NLP toolkit
- âš–ï¸ **Project:** [BlackStone](https://github.com/ICLRandD/Blackstone) - Spacy model pre UK legal texts
- ðŸ“‘ **Dataset:** [Legal BERT](https://huggingface.co/nlpaueb/legal-bert-base-uncased)

### Neo4j & Graph Databases

- ðŸŽ“ [Neo4j Graph Academy](https://graphacademy.neo4j.com/) (free courses)
- ðŸ“˜ **Kniha:** "Graph Databases" - Robinson, Webber, Eifrem
- ðŸ”— [Neo4j + LangChain Integration Guide](https://python.langchain.com/docs/integrations/graphs/neo4j_cypher)
- ðŸ“Š [Cypher Query Language Reference](https://neo4j.com/docs/cypher-manual/current/)

### SlovenskÃ© PrÃ¡vne Zdroje

- ðŸ“œ [Slov-Lex](https://www.slov-lex.sk/) - SlovenskÃ¡ legislatÃ­va
- âš–ï¸ JudikÃ¡ty slovenskÃ½ch sÃºdov
- ðŸ“° [Zbierka zÃ¡konov SR](https://www.zakonypreludi.sk/)
- ðŸ›ï¸ [NajvyÅ¡Å¡Ã­ sÃºd SR](https://www.nsud.sk/)

### AkademickÃ© Papers

- "Legal Information Extraction with NLP" (2021)
- "Automated Knowledge Graph Construction from Legal Documents" (2022)
- "Cross-lingual Legal NLP: Challenges and Opportunities" (2023)

## ðŸš€ MVP Prototyp

### MinimÃ¡lny funkÄnÃ½ systÃ©m

**Rozsah:**
- âœ… Input: Jeden zÃ¡kon (napr. ÄasÅ¥ ObÄianskeho zÃ¡konnÃ­ka)
- âœ… Extrakcia vÅ¡etkÃ½ch Â§ a ich textov
- âœ… IdentifikÃ¡cia krÃ­Å¾ovÃ½ch odkazov
- âœ… Extrakcia 3-5 typov entÃ­t
- âœ… Graf: Nodes (paragrafy, pojmy), Edges (odkazy, definÃ­cie)
- âœ… InteraktÃ­vna vizualizÃ¡cia

### Quick Start - MVP ImplementÃ¡cia

```python
# simple_legal_kg.py

import spacy
import networkx as nx
from pyvis.network import Network
import re

class SimpleLegalKG:
    def __init__(self):
        self.nlp = spacy.load("sk_core_news_lg")
        self.graph = nx.DiGraph()
    
    def extract_paragraphs(self, text: str):
        """Extrahuj Â§ ÄÃ­sla z textu"""
        pattern = r'Â§\s*(\d+)'
        return re.findall(pattern, text)
    
    def split_by_paragraph(self, text: str):
        """Rozdel text podÄ¾a paragrafov"""
        pattern = r'Â§\s*(\d+)[^\Â§]*'
        sections = re.finditer(pattern, text)
        
        results = []
        for match in sections:
            section_id = f"Â§{match.group(1)}"
            section_text = match.group(0)
            results.append((section_id, section_text))
        
        return results
    
    def build_graph(self, legal_text: str):
        """Vybuduj graf z prÃ¡vneho textu"""
        sections = self.split_by_paragraph(legal_text)
        
        for section_id, section_text in sections:
            # Pridaj node pre paragraf
            self.graph.add_node(
                section_id, 
                text=section_text[:200],  # Preview
                type="paragraph"
            )
            
            # NÃ¡jdi odkazy na inÃ© paragrafy
            references = self.extract_paragraphs(section_text)
            for ref in references:
                ref_id = f"Â§{ref}"
                if ref_id != section_id:
                    self.graph.add_edge(
                        section_id, 
                        ref_id, 
                        type="references"
                    )
    
    def visualize(self, output_file: str = "legal_kg.html"):
        """Vytvor interaktÃ­vnu vizualizÃ¡ciu"""
        net = Network(
            height="750px", 
            width="100%", 
            directed=True,
            notebook=False
        )
        
        # Styling
        net.barnes_hut(gravity=-80000, central_gravity=0.3)
        
        # Load from NetworkX
        net.from_nx(self.graph)
        
        # Customize nodes
        for node in net.nodes:
            node["color"] = "#97C2FC"
            node["size"] = 25
            if node.get("type") == "paragraph":
                node["shape"] = "box"
        
        # Save
        net.show(output_file)
        print(f"Graf uloÅ¾enÃ½ do: {output_file}")
    
    def query_connections(self, paragraph_id: str, depth: int = 2):
        """NÃ¡jdi prepojenÃ© paragrafy"""
        if paragraph_id not in self.graph:
            return []
        
        # BFS na nÃ¡jdenie spojenÃ½ch nodov
        connected = nx.single_source_shortest_path_length(
            self.graph, 
            paragraph_id, 
            cutoff=depth
        )
        return list(connected.keys())

# PouÅ¾itie
if __name__ == "__main__":
    # NaÄÃ­taj prÃ¡vny text
    with open("zakon.txt", "r", encoding="utf-8") as f:
        legal_text = f.read()
    
    # Vytvor knowledge graph
    kg = SimpleLegalKG()
    kg.build_graph(legal_text)
    kg.visualize()
    
    # Query
    connections = kg.query_connections("Â§123", depth=2)
    print(f"Paragrafy prepojenÃ© s Â§123: {connections}")
```

### Spustenie MVP

```bash
# Priprav sample legal text
echo "Â§1 TÃ¡to zmluva sa riadi Â§ 2 a Â§ 5..." > zakon.txt

# Spusti MVP
python simple_legal_kg.py

# Otvor legal_kg.html v prehliadaÄi
```

## ðŸ—ºï¸ Roadmap

### FÃ¡za 1: MVP (4-6 tÃ½Å¾dÅˆov)
- [ ] Basic paragraph extraction
- [ ] Simple cross-reference detection
- [ ] NetworkX graph construction
- [ ] Pyvis visualization
- [ ] CLI interface

### FÃ¡za 2: AI Integration (6-8 tÃ½Å¾dÅˆov)
- [ ] LangGraph workflow setup
- [ ] LLM-based entity extraction
- [ ] Relation extraction s confidence scores
- [ ] Neo4j migration
- [ ] Prompt optimization pre slovenÄinu

### FÃ¡za 3: Advanced Features (8-12 tÃ½Å¾dÅˆov)
- [ ] Semantic search
- [ ] Conflict detection (protireÄivÃ© Â§)
- [ ] Historical versioning
- [ ] Multi-document linking
- [ ] Q&A chatbot nad grafom
- [ ] Automatic summarization

### FÃ¡za 4: Production (12+ tÃ½Å¾dÅˆov)
- [ ] Web dashboard (Dash/Streamlit)
- [ ] REST API (FastAPI)
- [ ] User authentication
- [ ] Batch processing
- [ ] Performance optimization
- [ ] Deployment (Docker + Cloud)

## ðŸ“Š Metriky ÃšspeÅ¡nosti

- **Entity Extraction Accuracy:** > 90%
- **Relation Extraction F1:** > 85%
- **Graph Completeness:** > 95% cross-references captured
- **Query Response Time:** < 200ms
- **Visualization Load Time:** < 3s pre 500 nodes

## ðŸ¤ Prispievanie

Contributions sÃº vÃ­tanÃ©! ProsÃ­m pozri [CONTRIBUTING.md](CONTRIBUTING.md).

## ðŸ“„ Licencia

MIT License - pozri [LICENSE](LICENSE) pre detaily.

## ðŸ‘¥ Autori

- Tvoje meno - Initial work

## ðŸ™ PoÄakovanie

- LangChain & LangGraph community
- Neo4j Graph Academy
- Spacy SK model contributors
- Legal NLP research community

---

**PoznÃ¡mka:** Tento projekt je vo vÃ½voji. OdporÃºÄame zaÄaÅ¥ s MVP prototypom a iteratÃ­vne pridÃ¡vaÅ¥ funkcie podÄ¾a roadmapy.

**Kontakt:** your.email@example.com

**DokumentÃ¡cia:** [Wiki](https://github.com/your-username/legal-knowledge-graph/wiki)
